{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec65c075-6a5a-4379-9c69-8420430dd982",
   "metadata": {},
   "source": [
    "## Building Environments in Aviary\n",
    "\n",
    "In this tutorial we're going to focus on the GSM8K environment [1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b71f7dbb-7dc5-4f53-bd36-046062973757",
   "metadata": {},
   "outputs": [],
   "source": [
    "from aviary.env import Environment, Frame, TaskDataset\n",
    "from pydantic import BaseModel, ConfigDict, Field, field_validator \n",
    "from aviary.gsm8k.env import CalculatorEnvConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8afcb60e-1b4b-48d4-9c78-a56794e75aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TYPE_CHECKING, Literal\n",
    "import contextlib\n",
    "\n",
    "\n",
    "\n",
    "from aviary.message import Message\n",
    "from aviary.tools import Tool, ToolRequestMessage, ToolResponseMessage\n",
    "\n",
    "class CalculatorEnv(Environment[None]):\n",
    "    def __init__(\n",
    "        self,\n",
    "        problem_id: str,\n",
    "        problem: str,\n",
    "        answer: float,\n",
    "        config: CalculatorEnvConfig | None = None,\n",
    "    ):\n",
    "        # The problem is not part of the state because it is always the same.\n",
    "        # Putting it in the state would imply it is somehow affected by .step()\n",
    "        # or re-initialized by .reset().\n",
    "        self.problem_id = problem_id\n",
    "        self.problem = problem\n",
    "        self.answer = float(answer)\n",
    "\n",
    "        self.config = config if config is not None else CalculatorEnvConfig()\n",
    "\n",
    "        self.calc_tool = Tool.from_function(self.calculator)\n",
    "        self.check_tool = Tool.from_function(self.check_answer)\n",
    "        self.tools = [self.calc_tool, self.check_tool]\n",
    "\n",
    "    async def reset(self) -> tuple[list[Message], list[Tool]]:\n",
    "        self.state = None  # this environment is effectively stateless\n",
    "        return [Message(content=self.problem)], self.tools\n",
    "\n",
    "    async def step(\n",
    "        self, action: ToolRequestMessage\n",
    "    ) -> tuple[list[Message], float, bool, bool]:\n",
    "        if not action.tool_calls:\n",
    "            return (\n",
    "                [\n",
    "                    Message(\n",
    "                        content=\"Must call one of the provided tools (calculator or check_answer).\"\n",
    "                    )\n",
    "                ],\n",
    "                self.config.tool_failure_reward,\n",
    "                self.config.done_on_failure,\n",
    "                False,\n",
    "            )\n",
    "\n",
    "        valid_action, invalid_action = self.filter_invalid_tool_calls(action)\n",
    "\n",
    "        invalid_response_msgs = [\n",
    "            ToolResponseMessage.from_call(tool_call, content=\"\")\n",
    "            for tool_call in invalid_action.tool_calls\n",
    "        ]\n",
    "\n",
    "        if valid_action.tool_calls:\n",
    "            results = await self.exec_tool_calls(valid_action)\n",
    "            response_msgs = []\n",
    "            total_reward = 0.0\n",
    "            any_done = False\n",
    "\n",
    "            for tool_call, result in zip(valid_action.tool_calls, results, strict=True):\n",
    "                response, reward, done = json.loads(result.content)\n",
    "\n",
    "                response_msgs.append(\n",
    "                    ToolResponseMessage.from_call(tool_call, content=str(response))\n",
    "                )\n",
    "\n",
    "                total_reward += reward\n",
    "                any_done |= done\n",
    "\n",
    "            return response_msgs + invalid_response_msgs, total_reward, any_done, False\n",
    "\n",
    "        return (\n",
    "            invalid_response_msgs,\n",
    "            self.config.tool_failure_reward * len(invalid_response_msgs),\n",
    "            self.config.done_on_failure,\n",
    "            False,\n",
    "        )\n",
    "\n",
    "    def check_answer(self, answer: str) -> tuple[bool, float, Literal[True]]:\n",
    "        \"\"\"Check if the proposed answer is correct.\n",
    "\n",
    "        Args:\n",
    "            answer: Proposed answer.\n",
    "\n",
    "        Returns:\n",
    "            Three-tuple of if correct, associated reward (correct_reward if correct,\n",
    "                tool_failure_reward if tool failure, otherwise incorrect_reward), and\n",
    "                True indicating done.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            correct: bool = (\n",
    "                abs(float(answer) - self.answer)\n",
    "                / (abs(self.answer) + self.config.rel_tol)\n",
    "                < self.config.rel_tol\n",
    "            )\n",
    "            reward = (\n",
    "                self.config.correct_reward if correct else self.config.incorrect_reward\n",
    "            )\n",
    "        except ValueError:\n",
    "            return False, self.config.tool_failure_reward, True\n",
    "        else:\n",
    "            return correct, reward, True\n",
    "\n",
    "    def calculator(self, expr: str) -> tuple[float | str | None, float, bool]:\n",
    "        \"\"\"Calculate a mathematical expression.\n",
    "\n",
    "        Args:\n",
    "            expr (str): A valid python expression\n",
    "\n",
    "        Returns:\n",
    "            float: Result of the expression\n",
    "        \"\"\"\n",
    "        try:\n",
    "            expr = expr.strip()\n",
    "            result = eval(expr)\n",
    "            with contextlib.suppress(ValueError):\n",
    "                if int(result) == result:\n",
    "                    result = int(result)\n",
    "\n",
    "        except Exception:\n",
    "            return (\n",
    "                \"Error using calculator\",\n",
    "                self.config.tool_failure_reward,\n",
    "                self.config.done_on_failure,\n",
    "            )\n",
    "        return result, self.config.tool_success_reward, False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8817f9d3-78e7-47c6-9ba9-1b18bb30edd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import StrEnum\n",
    "import datasets\n",
    "\n",
    "\n",
    "# SEE: https://huggingface.co/datasets/openai/gsm8k\n",
    "GSM8K_PUBLIC_SOURCE = \"openai/gsm8k\"\n",
    "\n",
    "\n",
    "class GSM8kDataset(TaskDataset):\n",
    "    class Split(StrEnum):\n",
    "        train_full = \"train_full\"  #  full training set from OpenAI\n",
    "        train = \"train\"  # 80% of train_full (idx%5 != 0)\n",
    "        val = \"val\"  # 20% of train_full (idx%5 == 0)\n",
    "        test = \"test\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        split: Split | str,\n",
    "        config: CalculatorEnvConfig | dict | None = None,\n",
    "        hf_source: str = GSM8K_PUBLIC_SOURCE,\n",
    "    ):\n",
    "        if isinstance(config, dict):  # Serialized config\n",
    "            config = CalculatorEnvConfig(**config)\n",
    "        elif config is None:\n",
    "            config = CalculatorEnvConfig()\n",
    "        self.config = config\n",
    "\n",
    "        if isinstance(split, str):\n",
    "            split = self.Split(split)\n",
    "\n",
    "        src_df = self._get_df_from_hf(hf_source, split)\n",
    "\n",
    "        # Assign problem ID for the env\n",
    "        src_df[\"problem_id\"] = split.value + \"_\" + src_df.index.astype(str)\n",
    "\n",
    "        # attempt to extract a numerical answer\n",
    "        try:\n",
    "            src_df[\"answer_num\"] = src_df[\"answer\"].apply(\n",
    "                # answer is formatted as: <some text>\\n#### <answer_num>\n",
    "                lambda a: float(a.split(\"#### \")[1].replace(\",\", \"\"))\n",
    "            )\n",
    "        except Exception as e:\n",
    "            raise RuntimeError(\n",
    "                \"Failed to extract numerical answer from 'answer' column\"\n",
    "            ) from e\n",
    "\n",
    "        self.src_df = src_df\n",
    "\n",
    "    def _get_df_from_hf(self, hf_source: str, split: Split) -> \"pd.DataFrame\":\n",
    "        # All non-test splits are derived from train\n",
    "        hf_split = \"test\" if split == self.Split.test else \"train\"\n",
    "\n",
    "        kw = {}\n",
    "        if hf_source == GSM8K_PUBLIC_SOURCE:\n",
    "            kw[\"name\"] = \"main\"  # as opposed to \"socratic\"\n",
    "\n",
    "        src_df = (\n",
    "            datasets.load_dataset(hf_source, split=hf_split, **kw)\n",
    "            .to_pandas()\n",
    "            .reset_index(drop=True)\n",
    "        )\n",
    "        if split == self.Split.train:\n",
    "            src_df = src_df[src_df.index % 5 != 0]\n",
    "        elif split == self.Split.val:\n",
    "            src_df = src_df[src_df.index % 5 == 0]\n",
    "        return src_df\n",
    "\n",
    "    def get_new_env_by_idx(self, idx: int) -> CalculatorEnv:\n",
    "        row = self.src_df.iloc[idx]\n",
    "        return CalculatorEnv(\n",
    "            problem_id=row[\"problem_id\"],\n",
    "            problem=row[\"question\"],\n",
    "            answer=row[\"answer_num\"],\n",
    "            config=self.config,\n",
    "        )\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.src_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0302b166-8be3-45b5-a434-b612e4a56639",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Considering problem number 1\n",
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Can't instantiate abstract class CalculatorEnv without an implementation for abstract method 'export_frame'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m3\u001b[39m):\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mConsidering problem number \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 8\u001b[0m     env \u001b[38;5;241m=\u001b[39m \u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_new_env_by_idx\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m     obs, tools \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m env\u001b[38;5;241m.\u001b[39mreset()\n\u001b[1;32m     10\u001b[0m     ledger \u001b[38;5;241m=\u001b[39m ToolSelectorLedger(tools\u001b[38;5;241m=\u001b[39mtools, messages\u001b[38;5;241m=\u001b[39mobs)\n",
      "Cell \u001b[0;32mIn[5], line 70\u001b[0m, in \u001b[0;36mGSM8kDataset.get_new_env_by_idx\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_new_env_by_idx\u001b[39m(\u001b[38;5;28mself\u001b[39m, idx: \u001b[38;5;28mint\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m CalculatorEnv:\n\u001b[1;32m     69\u001b[0m     row \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msrc_df\u001b[38;5;241m.\u001b[39miloc[idx]\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mCalculatorEnv\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproblem_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mproblem_id\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproblem\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mquestion\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m        \u001b[49m\u001b[43manswer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43manswer_num\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     75\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: Can't instantiate abstract class CalculatorEnv without an implementation for abstract method 'export_frame'"
     ]
    }
   ],
   "source": [
    "from aviary.tools import ToolSelector, ToolSelectorLedger\n",
    "\n",
    "dataset = GSM8kDataset(split=\"train\")\n",
    "rewards = 0\n",
    "\n",
    "for i in range(3):\n",
    "    print(f'Considering problem number {i+1}\\n')\n",
    "    env = dataset.get_new_env_by_idx(i)\n",
    "    obs, tools = await env.reset()\n",
    "    ledger = ToolSelectorLedger(tools=tools, messages=obs)\n",
    "    tool_selector = ToolSelector(model_name=\"gpt-4o\")\n",
    "    for _ in range(10):\n",
    "        print(f'Observation is {obs}\\n')\n",
    "        action = await tool_selector(ledger.messages, tools)\n",
    "        print(f'Action is {action}\\n')\n",
    "        obs, reward, done, _ = await env.step(action)\n",
    "        ledger.messages.extend([action, *obs])\n",
    "        print(reward)\n",
    "        rewards += reward\n",
    "        if done:\n",
    "            break\n",
    "print(f'Total reward is {rewards}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "795bad9c-bdb3-4854-8549-7d6474dfe186",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "[1] Cobbe, K., Kosaraju, V., Bavarian, M., Chen, M., Jun, H., Kaiser, L., Plappert, M., Tworek, J., Hilton, J., Nakano, R. and Hesse, C., 2021. [Training verifiers to solve math word problems](https://arxiv.org/abs/2110.14168). arXiv preprint arXiv:2110.14168."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
